\documentclass[a4paper,10pt]{report}

\usepackage[in]{fullpage}
\usepackage{parskip}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage[backend=bibtex,style=numeric-comp,sorting=nyt,sortcites=true,maxnames=4]{biblatex}
\usepackage[section]{placeins}
\usepackage[color]{circus}
\usepackage{fixltx2e}
\usepackage{comment}

\usetikzlibrary{calc}

\CountDefsfalse

\title{A Framework for Verifying Safety-Critical Java Virtual Machines}
\author{James Baxter}
\date{}

\bibliography{literature} 

%TC:group zed 0 displaymath
%TC:group axdef 0 displaymath
%TC:group schema 1 displaymath
%TC:group circus 0 displaymath
%TC:group circusaction 0 displaymath
%TC:macroword \Circus 1 

\begin{document}
\maketitle

\begin{abstract}
  In recent years Java has been increasingly considered as a language
  for safety-critical embedded systems.
  However, some features of Java are unsuitable for such systems and
  this has resulted in the creation of Safety-Critical Java (SCJ).
  The different scheduling and memory management model of SCJ means
  that a specialised virtual machine is required to run SCJ programs.
  Given the safety-critical nature of the applications, it must be
  ensured that the virtual machine is correct, but so far no SCJ
  virtual machine has been formally verified.
  In this dissertation, we propose a framework for verification of SCJ
  virtual machines.
  We consider the differences between SCJ and standard Java, and
  discuss some of the existing virtual machines for SCJ.
  Seeing that many SCJ virtual machines precompile to native code, we
  then survey some of the literature on compiler correctness.
  Finally, we present some preliminary results identifying the
  requirements of the services of an SCJ virtual machine and
  constructing a formal model of those requirements.
\end{abstract}

\tableofcontents

\chapter{Introduction}

This chapter begins by explaining the motivation for the work
described in this dissertation.
Afterwards, the objectives of the work, which come from the
motivation, are described and, finally, the structure of the remainder
of this dissertation is described.

\section{Motivation}

Since its release in 1995, the Java programming
language~\cite{gosling2013} has increased in popularity and is now in
use on many platforms.
This popularity means that Java has been used in a wide variety of
areas including desktop applications, on the internet in the form of
Java applets, on smartcards~\cite{chen2000} and on mobile
devices~\cite{oracle2014}.
Several languages derived from Java have also been created, including
Scala~\cite{lausanne2015} and Ceylon~\cite{redhat2015}, as well as
older variants of Java such as MultiJava~\cite{clifton2006} and
Pizza~\cite{odersky1997}, which have in turn contributed to the
development of Java.
Scala adds functional programming features to Java, some of which have
been incorporated into Java 8.
Ceylon extends Java's type system with features such as union types,
allowing some common Java errors to be checked at compile time through
the type system.

One use of Java that is of particular interest is in embedded systems.
While early versions of Java were developed for programming,
particularly TV set-top boxes, the technology was not well received.
It was only in the growing sector of the internet that Java initially
found a market~\cite{horstmann2002}.
However, it was soon realised that the portability, modularity, safety
and security benefits of Java could be of great use in embedded
systems~\cite{mulchandani1998}.
This required the creation of specialised Java virtual machines as the
standard JVM is too large for most embedded systems.
Much research has gone into making smaller and smaller virtual
machines to widen the range of devices that Java can be used
on~\cite{caska2011,thomm2010}.

Many embedded systems are also real-time systems, and features of Java
such as the garbage collector and the concurrency model make it
unsuitable for real-time systems, for which strict guarantees about
timing properties must be made.
To address this issue the Real-Time Specification for Java
(RTSJ)~\cite{gosling2000} was created.
The RTSJ extends Java with a scoped memory model and a more
predictable scheduling system.

While the RTSJ addresses real-time requirements of embedded systems,
many embedded systems are also safety-critical.
For these conformance to certain standards, such as \mbox{DO-178C} and
ISO~26262, is required.
To support the development of safety-critical programs that meet these
requirements in Java, the Safety-Critical Java (SCJ)
specification~\cite{locke2013} has been created.
SCJ is a subset of the RTSJ that removes the features that cannot be
easily statically reasoned about, which means that features such as
the garbage-collected heap and dynamic class loading are absent from
SCJ.
This facilitates the creation of SCJ programs that fulfil formal
specifications; indeed work has already been done on developing
correct SCJ programs from formal specifications~\cite{cavalcanti2011,
  cavalcanti2013}.

On the other hand, even if it can be shown that SCJ programs are
correct, it must still be ensured those programs are executed
correctly.
In the case of Java-like languages, this generally means ensuring the
Java compiler and Java Virtual Machine (JVM) are correct.

Work has been done on modelling virtual machines for Java, and on the
formal correctness of compilers targeting those virtual machines.
Some of the most complete work in that area was by St\"{a}rk, Schmid
and B\"{o}rger~\cite{stark2001}, who present a model of the full Java
language and virtual machine, along with a formally verified compiler,
although for an older version of Java than is current.
Other work has also been done on modelling the JVM and Java
compilation using refinement techniques~\cite{duran2010}.
Additionally there has been work considering machine checked models of
Java virtual machines and compilers~\cite{lochbihler2012, nipkow2000,
  strecker2002}.
Work has also been done on the semantics of Java bytecode and
verification of standard JVMs~\cite{bertelsen2000, jones1998}.

However, SCJ has a number of differences from standard Java.
Firstly, as already indicated the SCJ memory model is rather different
to the standard Java memory model, abandoning the garbage collector in
favour of a scoped memory model.
Garbage collection is less predictable and often quite complex, and so
difficult to reason about and unsuitable for some of the strictest
certifiability requirements of safety-critical systems.
By contrast, the scoped memory model provides greater predictability
on when memory is freed.
Similarly, the SCJ approach to scheduling differs from that of
standard Java, using a preemptive priority scheduling approach rather
than the unpredictable scheduling of standard Java threads.
These differences of SCJ from standard Java mean that the standard JVM
is not suitable for running SCJ programs.
A specialised virtual machine is required.

In the case of virtual machines for embedded systems, the priorities
are usually size and speed, which generally results in machines that
are hard to verify.
Moreover, virtual machines that rely on interpreting bytecode are
unsuitable for real-time embedded systems as they are likely to be
slower.
An alternative method to run a Java program is to compile it to native
code and some authors have suggested doing so either
directly~\cite{schultz2003} or via C~\cite{varma2004}.
There are several virtual machines that take this approach including
Fiji VM~\cite{pizlo2009}, Icecap HVM~\cite{sondergaard2012} and
OVM~\cite{armbruster2007}.
This allows correct running of an otherwise correct SCJ program to be
viewed as a compiler verification problem.

There has been much research into compiler correctness.
Much of the work follows a commuting diagram approach, in which the
compilation is shown to be consistent with transformation between the
semantics of the source and target languages\cite{morris1973,
  thatcher1979}.
This approach is apparent in much of the early work such as that of
McCarthy and Painter~\cite{mccarthy1967}, as well as in more recent
work such as the CompCert project~\cite{leroy2009a, leroy2009b}.
There has also been work that follows this approach and employs
automated theorem provers~\cite{klein2006, milner1972, nipkow2000}.
They provide additional certainty that the proof is correct and can
also provide code generation facilities to allow creation of a working
compiler.

An alternative is the algebraic approach to compiler
verification~\cite{hoare1991, sampaio1993}, based on modelling
compilation using refinement calculi~\cite{back1981, morgan1990,
  morris1987}.
This approach appears to be less commonly used but has been applied to
Java~\cite{duran2005, duran2010} and hardware description
languages~\cite{perna2010, perna2011}.
This approach is also quite amenable to automation as it relies on
refinement laws that can be applied by a term rewriting system.

There is a clear need for formal verification of SCJ virtual machines
due to the safety-critical nature of the systems involved and the fact
that safety standards such as DO-178C require it at the highest safety
levels.
However, there appears to be little work done in that area and, as far
as we know, no SCJ virtual machine has been formally verified.

% explain that there is a gap with no verification for SCJ compilers
% for embedded systems

\section{Objectives}

Our objective is to construct a framework for verification of an SCJ
virtual machine.
It will provide the following resources for developers and verifiers:
\begin{itemize}
\item a specification of the requirements of an SCJ virtual machine,
\item a compilation strategy from Java bytecode to native C code,
\item a formal model of the virtual machine specification,
\item proofs for validation of the formal model and verification of
  the compilation strategy, and
\item a mechanisation of the model and proofs.
\end{itemize}

The first component required is a specification of the requirements
for an SCJ virtual machine.
This specification will shape the rest of the work and there is at
present no clear specification of what is required of an SCJ virtual
machine or how it differs from a standard Java virtual machine.
The specification of requirements needs to consider the requirements
imposed, both explicitly and implicitly, on virtual machines by the
SCJ specification~\cite{locke2013} as that provides the authoritative
source for information on SCJ.
It is also helpful to consider the approach taken by some existing SCJ
virtual machines on points where the SCJ specification is unclear.
The virtual machine must also meet the standard Java Virtual Machine
specification~\cite{lindholm2014} on points such as how to interpret
Java bytecode instructions.
There is much existing work on the semantics of Java bytecode that can
be used in our work~\cite{bertelsen2000, jones1998, stark2001}.

As many existing virtual machines for SCJ precompile programs to
native code in order to allow faster execution on embedded systems, it
seems wise to include that in our framework.
We will focus on compilation of Java bytecode to C as that is the
approach adopted by several existing virtual machines for embedded
systems, including Fiji VM~\cite{pizlo2009} and icecap
HVM~\cite{sondergaard2012}, and C is already widely used for embedded
systems software.

There are two main approaches to the specification and verification of
compilers: the commuting diagram approach and the algebraic approach.
The commuting diagram approach involves specifying the compiler as a
function from the source language to the target language and showing
that it is consistent with transformation between the semantics of the
source and target languages~\cite{morris1973, thatcher1979}.
This approach has been used in much of the work on compiler
correctness, including some of the earliest work~\cite{mccarthy1967}
and recent work such as that of the CompCert project~\cite{leroy2009a,
  leroy2009b}.

The algebraic approach involves defining the source and target
languages in the same specification space, and using proved
specialised rewrite rules to characterise compilation as model
transformation in the extended language.
This approach was first proposed in the early nineties by
Hoare~\cite{hoare1991} and further developed by
Sampaio~\cite{hoare1993, sampaio1993}.
The algebraic approach does not seem to be as popular as the commuting
diagram approach, but it does have the advantage that the
specification of the compilation strategy is correct by construction
as the rewrite rules that comprise it have all been proved.

In order to ensure that the specification is precise and to facilitate
proofs of its correctness, it must have a model written in some formal
specification language.
We will focus on using the \Circus{} specification
language~\cite{oliveira2009}, as it has been used in some of the
previous work on formalising SCJ~\cite{cavalcanti2011,
  cavalcanti2013}.
It is important that the correctness of the formal models and
compilation strategy can be shown via mathematical proof, which
requires the specification language to have a well-defined semantics.
\Circus{} has such a semantics, defined using the model of Unifying
Theories of Programming (UTP)~\cite{hoare1998}.

To prevent mistakes in the proofs, it is helpful to mechanise the
formal model and proofs.
There are various systems that can be used for this, but we will focus
on the proof assistant Isabelle~\cite{nipkow2002, nipkow2014}.
It has existing mechanisations of \Circus{}~\cite{feliachi2012} and
the UTP~\cite{foster2015}, and has been used in previous work
verifying compilers for Java-like languages~\cite{klein2006,
  strecker2002, lochbihler2010}, making it well placed for our work.

We have already made some progress towards the construction of the
proposed framework with a specification and formal model of the
requirements of an SCJ virtual machine.
It is expected that the model will be checked using a theorem prover;
our next task is then the development of a compilation strategy to
native code.

\section{Document Structure}

Having given a brief overview of the area of study and identified the
problem we wish to consider, the remainder of this dissertation
proceeds as follows.

In Chapter~\ref{literature-review-chapter} we examine the literature
on safety-critical virtual machines and compilers for Java-like
languages.
This includes a discussion of why a safety-critical variant of Java is
necessary and how it differs from standard Java.
We also explain why a specialised virtual machine is necessary for
SCJ.
This is followed by a survey of the existing virtual machines for
Safety-Critical Java and the techniques used in verifying compilers.

In Chapter~\ref{scjvm-services-chapter} we present an identification of the
requirements of SCJ virtual machine services, with a formal model of
those requirements in the \Circus{} specification language.
This is followed by a model of the an SCJ virtual machine core
execution environment in Chapter~\ref{cee-chapter}.

Finally, we conclude in Chapter~\ref{conclusions-chapter} by
summarising our contributions and mentioning the wider context of this
research.

% Description of SCJ and review of SCJ VMs - use stuff from JTRES
% paper, maybe extend it a bit Review the literature on compiler
% correctness - Two approaches: algebraic and commuting diagram -
% Consider each approach in a separate subsection and compare them -
% Make sure to describe the *approach* in detail, not what the authors
% did - Finish by looking at and comparing some of the work on Java
% compilation Present research proposal and preliminary results -
% Overall plan - requirements for an SCJVM - explain different parts
% of the diagram, mention CEE will be dealt with by later work -
% Present the identification of the requirements for the VM services
% from the JTRES paper - Discuss the formal model - similar to JTRES
% paper but room to go into more depth


\chapter{Compilers and Virtual Machines for Java-like languages in the
  Safety-critical Domain}
\label{literature-review-chapter}

This chapter begins with a discussion of why Java is being used in
safety-critical systems and the need for a specialised version of Java
for use in that area.
Then, in Section~\ref{scj-section} we cover the variant of Java
developed for safety-critical systems, how it differs from standard
Java and why a specialised virtual machine is required, before
discussing some of the existing virtual machines for that variant in
Section~\ref{virtual-machines-section}.

In Section~\ref{compiler-correctness-section} we survey some of the
literature on compiler correctness, and discuss the two main
approaches in Sections~\ref{commuting-diagram-subsection} and
\ref{algebraic-approach-subsection}, before seeing how the techniques
of compiler correctness have been applied to Java-like languages in
Section~\ref{java-compiler-correctness-subsection}.

In Section~\ref{circus-section}, we give an overview of the \Circus{}
specification language used for our virtual machine specification,
before concluding in Section~\ref{final-considerations-section}.

\section{Java for Safety-critical systems}
\label{java-safety-critical-section}

% provide motivation for SCJ, mentioning standard Java and RTSJ

In recent years Java has increasingly been considered as a language
for writing safety-critical software.
Other languages that are generally used in the safety-critical domain
are C/C++ and Ada; C and C++ impose challenges concerning reliable use
at the highest levels of safety~\cite{kornecki2009}, and the number of
Ada programmers is not very large~\cite{bissyande2013}.
While Java has not traditionally been seen as a language for
safety-critical systems, it was originally developed for the area of
embedded systems, particularly for use in television set-top boxes,
and has seen renewed interest in its use in embedded systems after
gaining popularity in programming for the
internet~\cite{mulchandani1998}.

There are, however, several issues with standard Java that make it
unsuitable for safety-critical systems.
Many safety critical systems are also real-time systems, which are
required to be predictable in their scheduling and use of memory.
However, standard Java uses a garbage-collected memory model, which
makes it hard to predict when memory may be freed or how long the
process of freeing memory may take.
Standard Java's thread model also lacks the predictability and control
that is required in real-time systems.

To rectify these problems the Real-Time Specification for Java
(RTSJ)~\cite{gosling2000} was created; it augments Java's memory and
scheduling models with a system of scoped memory areas and a
preemptive priority scheduler.
RTSJ also allows for the standard Java models to be used alongside its
own, making it suitable for a wide range of different real-time
applications.
On the other hand, this makes it hard to certify RTSJ applications and
thus renders the RTSJ unsuitable for use in the safety-critical
domain.

In order to allow certifiable safety-critical systems in Java, the
Safety-Critical Java (SCJ)~\cite{locke2013} specification was
developed.
SCJ is a subset of the RTSJ that leaves out the features from standard
Java that are difficult to certify such as the garbage collector.
SCJ also provides annotations that allow memory usage to be more
easily checked.
We discuss SCJ in more detail in the next section.

\section{Safety-Critical Java}
\label{scj-section}

SCJ removes the aspects of the RTSJ that make certification difficult,
including standard Java threads and the garbage collector.
This leaves scheduling and memory management models that are very
different to the models for standard Java and that, therefore, require
specialised virtual machines to support them.

SCJ defines three compliance levels to which programs and
implementations may conform.
Level 0 is the simplest compliance level.
It is intended for programs following a cyclic executive approach.
Level 1 lifts several of the restrictions of level 0, allowing
handlers that may trigger in response to external events and preempt
one another.
Level 2 is the most complex compliance level, allowing access to
real-time threads and suspension via \texttt{wait()} and
\texttt{notify()}.  

An SCJ program consists of one or more missions, which are collections
of schedulable objects that are scheduled by SCJ's priority scheduler.
Missions are run in an order determined by a mission sequencer
supplied by an SCJ program.
Running a mission proceeds in several phases, as shown in
Figure~\ref{phases-diagram}.

\begin{figure}[ht]
  \includegraphics[width=\textwidth]{phases.pdf}
  \caption{A diagram showing the phases of SCJ mission execution}
  \label{phases-diagram}
\end{figure}

The fist phase is initialisation, which consists of setting up the
schedulable objects controlled by the mission and creating any data
structures required for the mission.
Then the mission is executed by starting each of the schedulable
objects in the mission and waiting for a request to terminate the
mission.
When the mission is requested to terminate, each of the schedulable
objects in the mission is terminated and the mission's memory is
cleared.

The schedulable objects within a mission are asynchronous event
handlers that are released either periodically, at set intervals of
time, aperiodically, in response to a release request, or once at a
specific point in time (though handlers that are released once can
have a new release time set, allowing them to be released again).
At level 2 real-time threads are also allowed, which run continuously
from when they start until they finish, unless they are suspended or
interrupted by another schedulable object.

Each schedulable object has a priority and the highest priority object
that is eligible to run at each point in time is the object that runs.
This allows for simpler reasoning about order of execution and allows
for more urgent tasks to preempt less urgent tasks.

SCJ allows for assigning schedulable objects to ``scheduling
allocation domains'', where each domain consists of one or more
processors.
At Level 1, each scheduling allocation domain is restricted to a
single processor.
Hence, in scheduling terms, the system is fully partitioned.
This allows for mature single processor schedulability analysis to be
applied to each domain (although the calculation of the blocking times
when accessing global synchronised methods are different than they
would be on a single processor system due to the potential for remote
blocking~\cite{davis2011}).

SCJ deals with memory in terms of memory areas, which are Java objects
that provide an interface to blocks of physical memory called backing
stores.
Memory allocations in SCJ are performed in the backing store of the
memory area designated as the allocation context.
Each schedulable object has a memory area associated with it that is
used as the allocation context during a release of that object, and is
cleared after each release.
Each mission also has a mission memory area that can be used as an
allocation context by the schedulable objects of that mission, to
provide space for objects that need to persist for the duration of the
mission or to be shared between the schedulable objects.
The amount of memory required for the mission memory must be computed
ahead of time and specified by the programmer as part of writing the
mission, though there has been som work on automated computation of
worst case memory use for SCJ programs~\cite{andersen2013}.
There is also an immortal memory area where objects can be allocated
if needed for the entire running of the program (they are never
freed).
SCJ places restrictions on which objects an object may point to, so as
to avoid dangling pointers from being created.
Some examples of valid and invalid object references for some
asynchronous event handlers are shown in
Figure~\ref{stacks-areas-diagram}.

\begin{figure}[ht]
  \includegraphics[width=\textwidth]{Stacks-Areas.pdf}
  \caption{An example of the layout of memory areas for four
    asynchronous event handlers (ASEHs), showing possible valid and
    invalid references between them}
  \label{stacks-areas-diagram}
\end{figure}

This system of memory areas makes it easy to predict when memory is
freed.
It is not supported by standard JVMs as they do not provide memory
outside of the heap for allocation and lack a notion of allocation
context.
The SCJ memory manager also needs to provide a means of accessing raw
memory for the purposes of device access, but that section of the SCJ
standard is not yet finalised so we will not cover it here.
It can, however, be seen that any system of raw memory access is not
supported by most standard JVMs.

Moreover, dynamic class loading is not allowed in SCJ; all classes
used by the program must be loaded when the program starts.
This is because dynamic class loading may introduce time overheads
that are hard to predict and additional code paths that complicate
certification.
Finally, SCJ also disallows object finalisers as it is not always easy
to predict when they are run.

\section{Virtual Machines for Safety-Critical Java}
\label{virtual-machines-section}

% one subsection per machine

Because of the novel features of SCJ, briefly described in the
previous section, a specialised virtual machine that provides support
for allocation in memory areas and preemptive scheduling is required
for SCJ.
Although SCJ is a relatively recent development there have been
various virtual machines created for SCJ or variations of SCJ,
including icecap HVM~\cite{sondergaard2012}, Fiji VM~\cite{pizlo2009},
OVM~\cite{armbruster2007}, HVM\textsubscript{TP}~\cite{luckow2014} and
PERC Pico~\cite{atego2015, richard2010}.
These are each described in the following subsections.

\subsection{icecap HVM and HVM\textsubscript{TP}}

The icecap hardware-near virtual machine (HVM) was created as part of
the Certifiable Java for Embedded Systems Project~\cite{schoeberl2014}
and provides an open-source implementation of SCJ targeted at embedded
systems.
The approach taken by the HVM is one of precompiling Java bytecode to
C in order to allow for faster running programs with fewer memory
resources.
It includes an implementation of the SCJ libraries that covers most of
SCJ level 2, though only for a single processor implementation.
This implementation, however, cannot be easily decoupled from the
virtual machine itself.

The icecap HVM also provides a lightweight Java bytecode interpreter
and allows for interpreted code to be mixed with compiled code.
The reason for this is that the bytecode together with the interpreter
can often be smaller than the compiled code, though there is a
tradeoff for speed.
HVM\textsubscript{TP} is a modification of the icecap HVM's bytecode
interpreter to improve time predictability and ensure that bytecode
instructions are executed in constant time, which is important for
ensuring real-time properties of the system hold.

\subsection{Fiji VM}

Fiji VM is a proprietary Java implementation designed to run on
real-time embedded systems.
Similarly to the icecap HVM, Fiji VM uses the strategy of compiling to
C in order to improve performance.
However, Fiji VM is not specifically targeted at SCJ and works with a
range of libraries, including SCJ, RTSJ and the standard Java
libraries.
Fiji VM does have the advantage of high portability and multiprocessor
support, which is lacking in many other SCJ virtual machines.

The fact that Fiji VM works with the SCJ libraries and supports the
scoped memory model means it can run SCJ programs.
It does not necessarily support all aspects of SCJ properly though.

\subsection{OVM}

OVM was created at Purdue University as part of the PCES
project~\cite{baker2006}, to provide a virtual machine that can
execute real-time Java programs with a high level of performance on
embedded systems.
Similar to Fiji VM and icecap HVM, OVM follows the principle of
precompiling code for performance reasons, but translates Java to C++
instead of bytecode to C.

OVM also differs from the icecap HVM and Fiji VM in that it predates
SCJ.
It is written to implement the RTSJ, though it can still support SCJ
programs; indeed, an SCJ implementation for OVM was later
created~\cite{plsek2010}.
However, OVM does not appear to have kept up with more recent changes
to the draft SCJ standard.
OVM is, like icecap HVM, but unlike Fiji VM, single processor.

\subsection{PERC Pico}

PERC Pico is a product of Atego based on early ideas for SCJ, but uses
its own system of Java metadata annotations to ensure the safety of
scoped memory.
This systems of annotations provides additional information about how
memory is used so that it can be checked.
Similarly to other SCJ virtual machines, PERC Pico allows for
precompilation of Java code but targets executable machine code rather
than an intermediate programming language.
The metadata annotations are used to guide the compiler to produce
code that uses the correct scoped memory.
PERC Pico does not support the current SCJ standard, though it has
been suggested that it could be modified to do so~\cite{nilsen2011}.

To summarise, as far as we are aware there is one publicly available
virtual machine that has kept up with the developing SCJ
specification, the icecap HVM.
This is and, typically, virtual machines for SCJ will be, designed to
be very small and fast so as to be able to run on embedded systems.

As can be seen from the preceding discussion, a common technique to
run Java programs on embedded systems is to precompile them to native
code.
This means compiler correctness techniques must be considered in
verification of such a virtual machine; these techniques are discussed
in the next section.

\section{Compiler Correctness}
\label{compiler-correctness-section}

%TODO: mention approach of deriving a correct compiler described in
% www.cs.nott.ac.uk/~gmh/ccc.pdf

Due to the importance of compiler correctness, there has been much
research over the years in this area.
Most of the work done follows a similar approach, which we will term
the commuting-diagram approach as it is based on showing that a
particular diagram commutes.
We will discuss the commuting diagram approach in
Section~\ref{commuting-diagram-subsection}.
We also discuss a related approach based on deriving compilers and
their proofs of correctness from operational semantics in
Section~\ref{operational-approach-subsection}.

An alternative approach to compiler verification is the algebraic
approach developed in the early 90s.
It is based on the concepts of refinement calculi designed for
deriving software from specifications of behaviour.
We will explain the algebraic approach in
Section~\ref{algebraic-approach-subsection} and discuss how it differs
from the commuting-diagram approach.

We finish in Section~\ref{java-compiler-correctness-subsection} by
reviewing some of the literature on correctness of compilers for
Java-like languages.
We explain how the techniques of compiler correctness have been
applied in the case of Java and compare the different approaches.

\subsection{Commuting-diagram Approach}
\label{commuting-diagram-subsection}

Much of the work on compiler correctness can be seen as following the
approach identified by Lockwood Morris~\cite{morris1973}, and later
refined by Thatcher, Wagner and Wright~\cite{thatcher1979}.
The approach is essentially that a compiler correctness proof is a
proof that the diagram shown in Figure~\ref{commuting-diagram}
commutes, that is, $\gamma \circ \psi = \phi \circ \epsilon$.

\begin{figure}[ht]
  \begin{center}
    \begin{tikzpicture}
      \node[align=center] (S) at (0cm,3cm) {source\\language};
      \node[align=center] (T) at (4cm,3cm) {target\\language};
      \node[align=center] (M) at (0cm,0cm) {source\\meanings};
      \node[align=center] (U) at (4cm,0cm) {target\\meanings};
      
      \path (S) edge[->] node[align=center, above] {compile}
      node[align=center, below] {$\gamma$} (T); \path (S) edge[->]
      node[align=right, left] {source\\semantics}
      node[align=center,right] {$\phi$} (M); \path (T) edge[->]
      node[align=left, right] {target\\semantics} node[align=center,
      left] {$\psi$} (U); \path (M) edge[->] node[align=center, above]
      {encode} node[align=center, below] {$\epsilon$} (U);
    \end{tikzpicture}
  \end{center}
  \caption{The commuting diagram used in the traditional approach to
    compiler verification}
  \label{commuting-diagram}
\end{figure}

Lockwood Morris had the corners of the diagram as algebras, rather
than merely sets, with the functions between them being homomorphisms
in order to add additional structure to the proof.
This differs from the approach of some earlier works, particularly the
earliest work by McCarthy and Painter~\cite{mccarthy1967}, and instead
follows work such as that of Burstall and Landin~\cite{burstall1969}.

McCarthy and Painter's work featured a simple expression language with
addition, natural numbers and variables.
This was compiled to a simple 4-instruction single-register machine.
The arrows of the diagram were simple functions, rather than
homomorphisms, and the proof was performed using induction over the
source language.
This work laid the foundation for the study of compiler correctness.

Burstall and Landin show correctness of a compiler for the same source
and target languages as McCarthy and Painter; they use a more
algebraic approach that better matches what Lockwood Morris later
suggested.
Burstall and Landin's approach involved representing the source and
target languages, and their meanings, as algebras, with the
compilation functions as homomorphisms.
They target several intermediate machines in the proof of correctness.
Viewing the languages as algebras allows for simpler proofs as some of
the arrows of the commuting diagram can be wholly or partially derived
from the algebraic structure.
It was this goal of simplifying the proofs that led Lockwood Morris to
advocate the use of algebras and homomorphisms.

The overall goal of pursuing formal proofs of compiler correctness, as
proposed by McCarthy and Painter~\cite{mccarthy1967}, is to allow
machine-checked proofs of program correctness.
There has been work in that area, the earliest of which is that by
Milner and Weyhrauch~\cite{milner1972} who show the correctness of an
ALGOL-like language.
The proof of correctness was partially mechanised in the LCF theorem
prover~\cite{milner1972a} and the authors were of the opinion that the
proof was feasible and could be completed relatively easily.
A point to note is that Milner and Weyhrauch acknowledged the need for
some way of structuring the proof in order to make it amenable to
machine-checking.
This gives further support to the algebraic commuting diagram approach
advocated by Lockwood Morris.
Indeed, Milner and Weyhrauch explicitly followed that approach as they
were in discussions with Lockwood Morris.

One advantage to making proofs easily machine-checkable, apart from
the added certainty that the proof is correct, is that working
compilers can be created from the machine-checked proofs.
Code generation facilities are available with many theorem provers
such as those of Isabelle/HOL~\cite{haftmann2007} and
Coq~\cite{letouzey2003, letouzey2008}.
The fact that the commuting-diagram approach involves treating the
compilation as a function between algebras representing the source and
target languages fits well with this idea.
In this case, there is then a function defined in the mechanised logic
for the purposes of conducting proofs about it that can be readily
extracted to executable code.

The commuting-diagram approach has been followed in much of the
literature through the years, though not always with the algebraic
methods recommended by Lockwood Morris.
The basic structure of the commuting diagram is a fairly natural
approach to take, as seen by work such as that of the ProCoS
project~\cite{buth1992}.

Another piece of work that follows the commuting diagram approach is
that of Polak~\cite{polak1981}, who states that he is more interested
in verification of a ``real'' compiler rather than ``abstract code
generating algorithms'', and shows the correctness of a compiler for a
Pascal-like language.
This work focuses much more on pragmatic applications of the
commuting-diagram approach, leaving behind the algebraic ideas of
earlier papers.
It sets a precedent for a simpler verification approach based on
considering the functions in the commuting diagram.

The commuting diagram has also been used in recent work, some of the
most successful of which is that of CompCert~\cite{leroy2009a,
  leroy2009b, leroy2012}.
This is a project to create a fully verified realistic compiler for a
subset of C, using the theorem prover Coq~\cite{coq2004}.

There is also recent variation of the commuting-diagram approach, 
based on an operational semantics of the source
language~\cite{bahr2015}.
In this work, the operational semantics of the source language and
a way of relating the source and target semantics are used to derive a
different operational semantics of the source language acting on the
state of the target machine.
The semantics of the target language are then identified as part of
that operational semantics and it is transformed to extract a
compilation function.
This approach may be viewed as variant of the commuting-diagram
approach in which the compilation function is derived from the source
and target semantics and the relationship between them, rather than
being verified by those elements of the commuting-diagram.

\subsection{Algebraic Approach}
\label{algebraic-approach-subsection}

The second main approach to showing correctness of compilers is the
algebraic approach proposed by Hoare in 1991~\cite{hoare1991}, and
further developed by Sampaio~\cite{hoare1993, sampaio1993,
  sampaio1997}.
We note that the algebraic approach discussed in this section is
largely unrelated to the algebraic commuting-diagram approaches
mentioned in the previous section.

The algebraic approach to compilation derives from the concepts of
algebraic reasoning about programs and program refinement.
These concepts come from the idea, proposed by Hoare in
1984~\cite{hoare1984}, that programs can be thought of as predicates
and so the laws of predicate logic can be used to construct laws for
reasoning about programs~\cite{hoare1987}.
As an example of such a law for reasoning about programs, we present
below associativity of sequential composition,
Equation~\eqref{seq-comp-assoc}, and left and right unit of sequential
composition, namely, the program $\Skip$ that does nothing,
Equation~\eqref{skip-comp-identity}.
\begin{equation}
  \label{seq-comp-assoc}
  P;(Q;R) = (P;Q);R
\end{equation}
\begin{equation}
  \label{skip-comp-identity}
  P;\Skip = \Skip;P = P
\end{equation}

The notion of refinement is central to the algebraic approach to
compilation.
Refinement calculi have been developed, independently, by
Back~\cite{back1981}, Morris~\cite{morris1987} and
Morgan~\cite{morgan1990}, following from earlier concepts of program
transformation~\cite{bauer1976, balzer1976, standish1976, arsac1979}.
The basic idea is that there is a relation between programs that
captures the idea of one program being ``at least as good as'' another
or, to put it more precisely, at least as deterministic as another.
Languages and laws for reasoning about programs with this notion of
refinement can then be used to develop programs from specifications.
This means that certain aspects of a system can have a
nondeterministic specification and several different implementations
can refine that specification.

In using refinement to show the correctness of a compiler, the laws of
the specification language can be used to prove compilation refinement
laws.
These compilation laws can be used to transform the source programs
into some normal form that represents an interpreter for the target
language running the target code.
In other words, the code output by the compiler, when executed by on
the target machine, must be a refinement of the source program.
The compilation laws can be used to prove this refinement and at the
same time generate the target code.

As an example, consider the following refinement in which a simple
program that performs some arithmetic and stores the results into
variables is refined by a normal form representing the target machine
and code.
The symbol $\circrefines$ represents the refinement relation here.
\begin{equation}
  \circvar x, y, z \circspot x := (x + 5) \times (y + z) ; z := z + 1
  \circrefines
  \begin{aligned}
    &\circvar A, P, M \circspot P := 1; \circdo \\
    &\quad            P=1  \then A,    P := M[2],          2 \\
    &\quad \extchoice P=2  \then A,    P := A + M[3],      3 \\
    &\quad \extchoice P=3  \then M[4], P := A,             4 \\
    &\quad \extchoice P=4  \then A,    P := M[1],          5 \\
    &\quad \extchoice P=5  \then A,    P := A + 5,         6 \\
    &\quad \extchoice P=6  \then A,    P := A \times M[4], 7 \\
    &\quad \extchoice P=7  \then M[1], P := A,             8 \\
    &\quad \extchoice P=8  \then A,    P := M[3],          9 \\
    &\quad \extchoice P=9  \then A,    P := A + 1,         10 \\
    &\quad \extchoice P=10 \then M[3] := A,                11 \\
    &\circod ; \{ P = 11 \}
  \end{aligned}
\end{equation}
The normal form represents the behaviour of an interpreter for the
target code running in a target machine whose structure is defined
by the variables A, P, and M.
The variable $A$ represents a general-purpose register of the target
machine, $P$ represents the program counter of the target machine, and
$M$ is an array representing the memory of the target machine.
The normal form consists of a program that initialises $P$ to 1 and
then enters a loop in which the operation performed on each iteration
is dependent on the value of $P$.
The loop is exited when $P$ is set to a value for which there is no
operation and it is asserted that $P$ will be equal to 11 at the end
of the program.
Each of the statements of the source program corresponds to several
operations in the normal form as complex expressions are broken down
into simpler expressions that can be handled by instructions of the
target machine.

The compilation proceeds by first applying rules to simplify the
assignment statements.
The register $A$ is introduced at this stage by splitting assignments
of expressions to variables into two assignments that transfer the
values to and from $A$.
In this way, the assignments are transformed for the target machine
that only has instructions involving registers.
Particularly complex expressions such as $(x + 5) \times (y + z)$ are
handled by storing intermediate results in temporary variables.
In this case the result of the expression $y + z$ is placed in a
temporary variable when $P = 3$.
The variables used in the source program and introduced compilation
are later replaced with locations in the memory array $M$ in a data
refinement step.
This causes the variables $x$, $y$ and $z$ to be replaced with $M[1]$,
$M[2]$ and $M[3]$ respectively.
The temporary variable introduced to store the result of $y + z$ is
similarly replaced with $M[4]$.

Each of the assignment statements from is then refined by a normal
form with an explicit program counter $P$, that is incremented as part
of the assignment operation.
These normal forms are then combined together by the refinement rule
for sequential composition to create the normal form of the full
program.
The update of the program counter in this program is quite simple but
more complex updates would occur for conditionals or loops.

The power of the algebraic approach is that the compilation of
individual elements of the source language can be specified and proved
separately in different refinement laws.
The compilation can also be split into stages, with a set of
refinement laws for each stage to modularise the compilation.
The separate refinement laws can then be combined to form a
compilation strategy.

The first major work done using the algebraic approach was that of
Sampaio~\cite{sampaio1993}, who used it to specify a correct compiler
for a simple language that, nonetheless, covers all the constructs
available in most programming languages.
The target machine Sampaio used was a simple single-register machine
that bears similarity to most real processor architectures.
He mechanised the compiler in the OBJ3 term rewriting
system~\cite{goguen1988}, showing that working compilers can be easily
created from specifications using the algebraic approach.
However, the algebraic laws Sampaio used to prove correctness of the
compiler were taken as axioms.
Sampaio notes that they could be easily proved given a semantics for
the reasoning language.

Though there has not been much work done using the algebraic approach,
we single out the work of Perna~\cite{perna2010, perna2011}, showing
correctness of a compiler for a hardware description language.
The compilation takes high-level descriptions of hardware written in
Handel-C and transforms them into systems of basic hardware components
connected by wires.
The algebraic approach works well here as the target language is a
subset of the source language, albeit in a different form.
Perna was able to handle features not covered by most other works on
hardware compilation, such as parallelism with shared variables.
Also, whereas Sampaio took the basic algebraic laws as axioms, Perna
proved the laws from a semantics given using the Unifying Theories of
Programming (UTP) model~\cite{hoare1998}.
There has also been work on the correctness of Java compilers using
the algebraic approach.
This is considered in the next section, where we consider compiler
correctness for Java-like languages.

\subsection{Correctness of Java Compilers}
\label{java-compiler-correctness-subsection}

The popularity of Java has meant that there has been plenty of work on
formalising Java and the JVM~\cite{hartel2001}, but there have been
relatively few works on formally verified compilers for Java-like
languages.
However, the work that has been done uses both of the two main
approaches and covers most of the features of Java.

Some of the earliest and most thorough work is that by S\"{a}rk,
Schmid and B\"{o}rger~\cite{stark2001}, who formalise most of Java and
the JVM before specifying and showing the correctness of a compiler
for Java.
The approach taken by them uses Abstract State Machines (ASMs) to
specify the source and target languages.
The ASMs give an operational semantics to Java and the JVM, describing
how each construct affects the running of the program.
The languages are each specified by multiple ASMs, beginning with an
imperative core, then adding classes, objects, exceptions and,
finally, threads.

Although this approach is called the ASM approach, it becomes clear
from the definition of compiler correctness given in terms of a
mapping between ASMs that this work ultimately follows the
commuting-diagram approach.
This work leaves parts of the proof incomplete (in particular,
compilation of threads is not addressed) and applies to an old version
of Java.
This is, nevertheless, an admirable attempt at producing a verified
Java compiler.

Work has also been done by Duran following the algebraic
approach~\cite{duran2005, duran2010}.
Duran's work specifies a compiler for a language called Refinement
Object-Oriented Language (ROOL)~\cite{borba2000}, which was created
for reasoning about object-oriented languages and bears much
similarity to Java.
ROOL features constructs for specifying and reasoning about programs
as well as object-oriented programming language constructs.
This means that the there are algebraic laws for ROOL, from which the
rewrite rules that form the basis of the algebraic approach can be
proved.
Duran's work adds further phases to Sampaio's compilation strategy in
order to deal with the object-oriented features, but does not consider
some other aspects of Java such as exceptions and threads.
Duran notes that other work has addressed some of those issues.

While the two works already discussed were not machine checked, there
have also been compiler correctness proofs for Java-like languages in
the Isabelle/HOL proof assistant.
The first of these was by Strecker~\cite{strecker2002}, showing
correctness of a compiler for a subset of Java called $\mu$Java, which
already had a formalisation of its semantics in
Isabelle/HOL~\cite{nipkow2000}.
This work was followed by Klein and Nipkow's work on a compiler for a
slightly larger subset of Java called Jinja~\cite{klein2006}, which
added exception handling.
Finally, Lochbihler~\cite{lochbihler2010} added threads to Jinja and
showed correctness of compilation for Java concurrency.
It is notable that this is the only work on Java compilation that
properly addresses concurrency.
All of these works follow the commuting diagram approach.

Though some work has been done on correct compilers for Java-like
languages and many virtual machines for SCJ adopt an approach of
compiling to native code, no work has been done on verifying that
compilation to native code.
Therefore, we will consider correctness of the compilation to native
code as part of our work on SCJ virtual machines.
We will follow the algebraic approach as it gives greater assurance of
correctness, as an additional function mapping source meanings to
target meanings is not required, and a good level of modularity, as
the compilation is split into separately proved rewrite rules.
In order to represent the normal form we require a specification
language and for that purpose will use \Circus{}, which is described
in the next section.

\section{\Circus{}}
\label{circus-section}

The \Circus{} specification language~\cite{oliveira2009} is based on
CSP~\cite{roscoe2011}, which is used to specify processes that
communicate over channels, and the Z notation~\cite{woodcock1996},
which is used to specify state and data operations.
A \Circus{} specification is made up of processes that communicate
over channels.
These channels may carry values of a particular type, or may be used
as flags for synchronisation or signalling between processes.
Each process may have state, and is made up of actions that operate on
that state and communicate over channels.

We illustrate the concepts of \Circus{} using as an example the
process for the real-time clock from some of the preliminary work on
the specification of an SCJ virtual machine.
The specification begins with a declaration of the channels that may
be used in the following processes.
Type declarations written in Z can also be included at the beginning
of a \Circus{} specification.
Here, we define a type $Time$ to be the set of natural numbers and
create a boolean datatype
%
\begin{zed}
  Time == \nat \\
  Bool ::= True | False \\
\end{zed}
%
We declare channels to represent interactions corresponding to calls
to methods to get the clock's time and precision, and set and clear
alarms.
Channels are also declared to model interactions with the hardware
that accept clock tick interrupts and read the time from the hardware
clock.
%
\begin{circus}
  \circchannel getTime, getPrecision, setAlarm : Time \\
  \circchannel clearAlarm \\
  \circchannel HWtick \\
  \circchannel HWtime : Time \\
\end{circus}
%
We also specify a constant to represent the clock's precision using a
Z axiomatic definition.
The value of the constant is required to be nonzero, but is otherwise
left unrestricted, so that any nonzero time value is a valid
instantiation.
%
\begin{axdef}
  precision : Time \where precision > 0
\end{axdef}
%
After the channel declarations, we can declare processes that use
them.
Here we declare the $RealtimeClock$ process.
It is a basic process, that is, its state is defined in Z, and its
behaviour using CSP constructs and Z data operations.
%
\begin{circus}
  \circprocess RealtimeClock \circdef \circbegin
\end{circus}
%
In this example, the state records the current time, whether an alarm
is set, and the time of the alarm that may be set.
An invariant specifies that if an alarm is set, then the time of the
alarm must not be in the past.
%
\begin{schema}{RTCState}
  currentTime  : Time \\
  alarmSet     : Bool \\
  currentAlarm : Time \\
\where
  alarmSet = True \implies \\
  \t1 currentAlarm \geq currentTime
\end{schema}
\begin{circusaction}
  \circstate RTCState
\end{circusaction}
%
The behaviour is described using actions, written in a mixture of Z
and CSP.
The first action is a Z initialisation operation, $Init0$.
Its final state is represented by variables obtained by placing a
prime on the names of the state components.
Here, the initialisation takes as input the initial time, represented
by the variable $initTime?$.
The current time is defined to be equal to the initial time and no
alarm is initially set.
The initial time of the alarm is arbitrary, that is,
nondeterministically chosen from elements of its type, since the
initialisation imposes no restrictions on it.
%
\begin{schema}{Init0}
  RTCState~' \\
  initTime?{} : Time \\
\where 
  currentTime' = initTime?{} \\
  alarmSet' = False \\
\end{schema}
%
The action $Init$, defined below, uses a CSP prefixing to specify an
input communication before the initialisation operation $Init0$.
The initial time of the clock is read from the hardware clock and then
the initialisation specified by the Z schema is performed.
%
\begin{circusaction}
  Init \circdef HWtime?initTime \then Init0
\end{circusaction}
%
The action that returns the current time simply uses CSP to output the
current time from the state over the $getTime$ channel.
The action ends with the special action $\Skip$, which indicates the
end of an action.
%
\begin{circusaction}
  GetTime \circdef getTime!currentTime \then \Skip
\end{circusaction}
%
Setting a new alarm is a more complex operation that involves Z
schemas that specify two different scenarios in which this operation
may be used.
In the first case, the new alarm is not in the past.
The symbol $\Delta$ denotes a change of state.
The operation stores the time of the new alarm and sets a flag to
indicate an alarm is set in this case.
%
\begin{schema}{SetAlarm0}
  \Delta RTCState \\
  newAlarm?{} : Time \\
\where
  newAlarm?{} \geq currentTime \\
  currentAlarm' = newAlarm?{} \\
  alarmSet' = True \\
  currentTime' = currentTime \\
\end{schema}
%
In the second case, the new alarm is in the past and so the alarm is
not set (we have omitted the error reporting for the sake of
simplicity).
The symbol $\Xi$ denotes that the state remains the same.
%
\begin{schema}{SetAlarm1}
  \Xi RTCState \\
  newAlarm?{} : Time \\
\where
  newAlarm?{} < currentTime \\
\end{schema}
%
The two Z schemas are combined using a logical disjunction, allowing
either to specify the behaviour when a request to set the alarm takes
place.
%
\begin{circusaction}
  SetAlarm \circdef setAlarm?newAlarm \\
  \t1 \then\ \lschexpract SetAlarm0 \lor SetAlarm1 \rschexpract
\end{circusaction}
%
In addition to Z and CSP constructs, \Circus{} also has other
constructs more familiar to programmers, such as if statements and do
loops.
One of these constructs, the assignment operator, is used in the
action that clears the current alarm to update part of the state
without requiring a Z schema.
The alarm is cleared by simply setting $alarmSet$ to $False$, without
updating any other state variables.
%
\begin{circusaction}
  ClearAlarm \circdef clearAlarm \then alarmSet := False
\end{circusaction}
%
Each of the actions the process can perform are joined together with
the CSP external choice operator, which chooses an action to take
based on the channel communications that the environment is willing to
perform.
This includes the actions above, as well as some other actions that
have been omitted here.
The choice is repeated in a loop.
%
\begin{circusaction}
  Loop \circdef \left( GetTime \extchoice SetAlarm \extchoice
    ClearAlarm
    \extchoice \cdots \right) \\
  \t1 \circseq Loop
\end{circusaction}
%
The \Circus{} process then ends with the main action that specifies
the overall behaviour of the process.
Here, the process simply performs the initialisation and then enters
the loop.
%
\begin{circusaction}
  \circspot Init \circseq Loop
\end{circusaction}
\begin{circus}
  \circend
\end{circus}

In addition to the constructs presented here \Circus{} also contains
operators for composing processes in parallel, with or without
synchronisation on channels.
These operators are used both to specify actual parallelism and to
represent composition of requirements.
In this way several \Circus{} specifications of individual components
can be combined to form a specification of the entire system.

% for the thesis add a more comprehensive description of Circus with a
% description of process operators and tables of operator descriptions

\section{Final Considerations}
\label{final-considerations-section}

% summarise the problem and how to solve it

We have seen that Java is increasingly being considered as a language
for safety-critical embedded systems and that the modifications to
Java required to make it suitable for such systems require a
specialised virtual machine.
The developing Safety-Critical Java specification has several
differences from standard Java, particularly in the areas of
scheduling and memory management, that make standard JVMs unsuitable
for running SCJ programs.
We have considered several virtual machines that have been developed
for running SCJ programs and noted that none of them has been formally
verified and that most of them adopt an approach of precompiling
programs to native code.

With that in mind, we have considered the techniques used to verify
the correctness of compilers and found that there are two main
approaches: the commuting-diagram approach and the algebraic approach.
In the commuting-diagram approach the source semantics, target
semantics, compilation function, and a function mapping the source
meanings to the target meanings, are shown to commute.
This approach is popular and has had much research done on it but
relies on the definition of the function from the source meanings to
the target meanings.

The algebraic approach defines the source and target languages within
the same specification language, which is additionally equipped with a
refinement relation between programs.
Laws of the specification language are then used to prove refinement
rules that are applied according to some compilation strategy.
The algebraic approach has the advantage that it does not require the
additional function that is required in the commuting-diagram
approach, since the source and target languages are defined in terms
of the same specification language.
The algebraic approach also permits a modular approach to proof and
allows for the compiler to be easily implemented by application of the
refinement rules using a term rewriting system.

Given the considerations above, we have decided to adopt the algebraic
approach when specifying the compilation to native code employed by
many SCJ virtual machines.
This means that a specification language is required in which to
define the source and target languages, as well as for the purposes of
specifying other aspects of the virtual machine.
We have chosen \Circus{} as the specification language as it contains
a wide variety of constructs that allow for specification of both data
and behaviour, has a well defined semantics with many laws already
proved, and has been used for previous work on the specification of
SCJ programs.
\Circus{} also has some existing mechanisation and tool support, which
can help give greater assurance of the correctness of specifications.

\chapter{Safety-Critical Java Virtual Machine Services}
\label{scjvm-services-chapter}

In order to reason about a Safety-Critical Java virtual machine
(SCJVM), we first require an identification of the the requirements of
an SCJVM and a formal model of those requirements.
For the purposes of our model, we view an SCJVM as being composed of
the components illustrated in Figure~\ref{scjvm-services-fig}.
An SCJVM is divided into two main parts:~the core execution
environment and the SCJVM services.
These parts may also make use of the services of an underlying
operating system or hardware abstraction layer.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}

    \coordinate (width)  at (10cm,0cm);
    \coordinate (height) at (0cm,7cm);

    \path (0,0) -- (height)
    coordinate[pos=0.18] (OS boundary)
    coordinate[pos=0.20] (VM part bottom)
    coordinate[pos=0.57] (VM part top)
    coordinate[pos=0.60] (API boundary)
    coordinate[pos=0.82] (App boundary);
    
    \path (VM part bottom) -- (VM part top)
    coordinate[pos=0.7] (VM Service top);

    \path (VM part bottom) -- (VM part top)
    coordinate[pos=0.85] (VM Services ypos);

    \path (0,0) -- (width)
    coordinate[pos=0.04] (CEE left)
    coordinate[pos=0.27] (CEE right)
    coordinate[pos=0.29] (VM Services left)
    coordinate[pos=0.96] (VM Services right)
    coordinate[pos=0.17] (VM Service width)
    coordinate[pos=0.04] (VM Service sep);

    \path (VM Services left) -- (VM Services right)
    coordinate[pos=0.5] (VM Services xpos);

    \path (0,0) to node[pos=0.5] (mid) {} (width);
    \path (0,0) to node[pos=0.25] (quart) {} (width);

    \draw (0,0) rectangle (width |- height);

    \draw (OS boundary) -- ++(width);
    \path (0,0) rectangle node[pos=0.5] (OS) {} (width |- OS boundary);
    \draw (mid |- API boundary) rectangle node[pos=0.5] (API) {} (width |- App boundary);
    \draw (App boundary) -- ++(width);
    \path (App boundary) rectangle node[pos=0.5] (App) {} (width |- height);

    \path (quart |- API boundary) rectangle node[pos=0.4] (SCJVM) {} (quart |- App boundary);
    \draw (CEE left |- VM part bottom) rectangle node[pos=0.5] (CEE) {} (CEE right |- VM part top);
    \draw (VM Services left |- VM part bottom) rectangle (VM Services right |- VM part top);
    \coordinate (VM Services) at (VM Services xpos |- VM Services ypos);

    \node[align=center] at (App)   {SCJ Application};
    \node[align=center] at (API)   {SCJ\\Infrastructure\\and API};
    \node[align=center] at (SCJVM) {SCJ\\Virtual Machine};
    \node[align=center] at (CEE)   {Core\\Execution\\Environment};
    \node[align=center] at (OS)    {Operating System/Hardware Abstraction Layer};
    
    \foreach \x in {1,...,3}
    \pgfmathsetmacro{\a}{0.333*(\x - 1)}
    \pgfmathsetmacro{\b}{0.333*\x}
    \path ($(VM Services left) + (VM part bottom)!0.07!(VM part top)$) -- 
    node[pos=\a] (VM Service \x start) {}
    node[pos=\b] (VM Service \x end) {}
    ($(VM Services right) + (VM part bottom)!0.07!(VM part top) - (VM Service sep)$);

    \foreach \x in {1,...,3} 
    \draw ($(VM Service \x start) + (VM Service sep)$)
    rectangle node[pos=0.5] (VM Service \x) {}
    (VM Service \x end |- VM Service top);

    \node[align=center] at (VM Services)  {VM Services};
    \node[align=center] at (VM Service 1) {Memory\\Manager};
    \node[align=center] at (VM Service 2) {Scheduler};
    \node[align=center] at (VM Service 3) {Real-time\\Clock};
  \end{tikzpicture}
  \caption{A diagram showing the structure of an SCJVM and its
    relation to the SCJ infrastructure and the operating
    system/hardware abstraction layer, focusing on the SCJVM services}
  \label{scjvm-services-fig}
\end{figure}

The core execution environment is responsible for the execution of
Java bytecode, whether that be via interpretation, just-in-time
compilation or ahead-of-time compilation.
The core execution environment must also manage structure that
relates to the execution of bytecode instructions, such as the
representation of classes and objects.
The core execution environment is the part of the SCJVM that our
compilation strategy will act upon.

The SCJVM services represent the additional services that must be
offered by an SCJVM in order to support the SCJ infrastructure.
These services may be supplied as standalone services and so do not
need to be handled by the compilation strategy.
We view the virtual machine services as being divided into three areas: 
\begin{itemize}
\item the memory manager, which manages backing stores for memory areas and
  allocation within them;
\item the scheduler, which manages threads and interrupts, and allows for
  implementation of SCJ event handlers; and
\item the real-time clock, which provides an interface to the system real-time
  clock.
\end{itemize}
Each of these services is used either by the core execution environment or by
the SCJ infrastructure; some of the services also rely on each other.  For
example, the scheduler must update the allocation context in the memory manager
when performing a thread switch.

A model of the core execution environment will be presented in 
Chapter~\ref{cee-chapter}.
In this chapter, we present the requirements for the SCJVM services as
a formal model written in the \Circus{} specification language.
Each part of the model will be presented in a separate section:~the
memory manager in Section~\ref{memory-manager-section}, the scheduler
in Section~\ref{scheduler-section}, and the real-time clock in
Section~\ref{realtime-clock-section}.
Finally, the parts of the model are combined to form a complete model
of the SCJVM services in Section~\ref{scjvm-services-section}.

The memory manager model has be partially proved using Z/Eves.
The theorems about the memory manager that have been proved with
Z/Eves are included in the model in this chapter and mostly standard
theorems from CZT's verification condition generator.
The Z/Eves proof scripts for these theorems can be found in
Appendix~\ref{memory-manager-proofs-section}.
Many additional lemmas about objects in the Z/Eves mathematical
toolkit have been proved in the course of proving the memory manager.
As these could be of use outside our work, we have included them
separately in Appendix~\ref{additional-lemmas-section} with their
proofs in Appendix~\ref{addtional-lemmas-proofs-section}.

Part of an earlier version of this model was presented at the 13th
International Workshop on Java Technologies for Real-time and Embedded
Systems~\cite{baxter2015a} with the full earlier version made available
as a technical report~\cite{baxter2015}.

\input{\string~/SCJ-VM/James/memorymanager.zed}

\input{\string~/SCJ-VM/James/scheduler.zed}

\input{\string~/SCJ-VM/James/realtimeclock.zed}

\input{\string~/SCJ-VM/James/scjvmservices.zed}

\chapter{The Core Execution Environment}
\label{cee-chapter}

This chapter covers the second component of an SCJVM, which is the
core execution environment (CEE).
The CEE is reponsible for executing Java bytecode instructions.
Additionally, the CEE must be aware of the structure of Java objects
and classes in order to properly handle some bytecode instructions.
The CEE also manages the flow of execution surrounding the execution
of bytecode instructions, including handling safelet setup and mission
execution.

As shown in Figure~\ref{cee-fig}, we view the core execution
environment as being divided into four parts:
\begin{itemize}
\item the code area, which stores the classes and bytecode
  instructions that are statically loaded on SCJVM startup,
\item the memory, which manages the information about objects created
  during execution,
\item the interpreter, which handles execution of bytecode
  instructions, and
\item the launcher, which coordinates the startup of the SCJVM, the
  execution of missions and the execution of methods in the
  interpreter.
\end{itemize}

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}

    \coordinate (width)  at (10cm,0cm);
    \coordinate (height) at (0cm,7cm);

    \path (0,0) -- (height)
    coordinate[pos=0.18] (OS boundary)
    coordinate[pos=0.20] (VM part bottom)
    coordinate[pos=0.57] (VM part top)
    coordinate[pos=0.60] (API boundary)
    coordinate[pos=0.82] (App boundary);
    
    \path (VM part bottom) -- (VM part top)
    coordinate[pos=0.7] (CEE part top);

    \path (VM part bottom) -- (VM part top)
    coordinate[pos=0.85] (CEE ypos);

    \path (0,0) -- (width)
    coordinate[pos=0.04] (CEE left)
    coordinate[pos=0.76] (CEE right)
    coordinate[pos=0.78] (VM Services left)
    coordinate[pos=0.96] (VM Services right)
    coordinate[pos=0.01] (CEE part sep);

    \path (CEE left) -- (CEE right)
    coordinate[pos=0.5] (CEE xpos);

    \path (0,0) to node[pos=0.5] (mid) {} (width);
    \path (0,0) to node[pos=0.25] (quart) {} (width);

    \draw (0,0) rectangle (width |- height);

    \draw (OS boundary) -- ++(width);
    \path (0,0) rectangle node[pos=0.5] (OS) {} (width |- OS boundary);
    \draw (mid |- API boundary) rectangle node[pos=0.5] (API) {} (width |- App boundary);
    \draw (App boundary) -- ++(width);
    \path (App boundary) rectangle node[pos=0.5] (App) {} (width |- height);

    \path (quart |- API boundary) rectangle node[pos=0.4] (SCJVM) {} (quart |- App boundary);
    \draw (CEE left |- VM part bottom) rectangle (CEE right |- VM part top);
    \draw (VM Services left |- VM part bottom) rectangle node[pos=0.5] (VM Services) {} (VM Services right |- VM part top);
    \coordinate (CEE) at (CEE xpos |- CEE ypos);

    \node[align=center] at (App)   {SCJ Application};
    \node[align=center] at (API)   {SCJ\\Infrastructure\\and API};
    \node[align=center] at (SCJVM) {SCJ\\Virtual Machine};
    \node[align=center] at (CEE)   {Core Execution Environment};
    \node[align=center] at (VM Services)  {SCJVM\\Services};
    \node[align=center] at (OS)    {Operating System/Hardware Abstraction Layer};

    \foreach \x in {1,...,4}
    \pgfmathsetmacro{\a}{0.25*(\x - 1)}
    \pgfmathsetmacro{\b}{0.25*\x}
    \path ($(CEE left) + (VM part bottom)!0.07!(VM part top)$) -- 
    node[pos=\a] (CEE part \x start) {}
    node[pos=\b] (CEE part \x end) {}
    ($(CEE right) + (VM part bottom)!0.07!(VM part top) - (CEE part sep)$);

    \foreach \x in {1,...,4} 
    \draw ($(CEE part \x start) + (CEE part sep)$)
    rectangle node[pos=0.5] (CEE part \x) {}
    (CEE part \x end |- CEE part top);

    \node[align=center] at (CEE part 1) {\small Code\\Area};
    \node[align=center] at (CEE part 2) {\small Memory};
    \node[align=center] at (CEE part 3) {\small Interpreter};
    \node[align=center] at (CEE part 4) {\small Launcher};
  \end{tikzpicture}
  \caption{A diagram showing the structure of an SCJVM and its
    relation to the SCJ infrastructure and the operating
    system/hardware abstraction layer, focusing on the core execution
    environment}
  \label{cee-fig}
\end{figure}

This chapter will begin with a brief explanation of the assumptions 
made and the bytecode subset used in creating this model in
Section~\ref{cee-assumptions-section}.
Then each part of the \Circus{} model of the core execution environment is
presented in a separate section:~the class structure in
Section~\ref{cee-classes-section}, the code area in
Section~\ref{cee-code-area-section}, the object structure and memory
in Section~\ref{cee-memory-section}, the stack frame structure in
Section~\ref{cee-stack-frames-section}, the interpreter in
Section~\ref{cee-interpreter-section}, and the launcher in
Section~\ref{cee-launcher-section}.
Finally the parts are drawn together into the complete model in
Section~\ref{complete-cee-section}.

\section{Assumptions and Bytecode Subset}
\label{cee-assumptions-section}

Due to the complexity of the JVM and Java bytecode, we have chosen not
to model the whole of Java bytecode.
We instead model a subset of Java bytecode that we believe is
sufficient to express a wide variety of SCJ programs and illustrate
how further features may be added, but small enough to permit
effective reasoning.
We describe our bytecode subset and further assumptions that we have
made in creating the SCJVM model in this section.

Our first major assumption is that execeptions are not handled,
errors in the SCJVM are instead handled by simply aborting execution.
This is justified as the exception handling mechanism of Java is quite
complex and the correct application of formal methods should eliminate
errors in the SCJVM.
This means that that the bytecode instructions that relate to throwing
and catching exceptions are not included in our bytecode subset.

Another major assumption we have made is that all values consist of
only a single virtual machine word.
This means that \texttt{long} and \texttt{double} values are not
handled.
Any SCJ API methods that take \texttt{long} or \texttt{double}
arguments are viewed as taking \texttt{int} or \texttt{float} instead.
The reason for this assumption is that handling of two word values
would complicate many bytecode instructions while adding little to
the power of the bytecode subset except that larger ranges of values
could be handled, which makes little difference at the level of the
formal model.

Further, we do not make a distinction between the different virtual
machine types in our bytecode instructions but instead supply
instructions that handle values as object references.
This makes sense as many of the instructions behave the same for
different types so it would introduce a lot of duplication to the
model if, for example, both the \texttt{areturn} \and \texttt{ireturn}
instructions were to be included.
The arithmetic instructions are also quite simple and type specific so
we have excluded them from our model for the sake of brevity; it
should be fairly simple to add them if necessary.

We also do not consider static methods and fields since that would add
some complexity to our model and most of the considerations are
covered by non-static methods and fields.

Because we are considering SCJ bytecode, some requirements of SCJ
permit further simplifications to our bytecode subset.
The \texttt{invokedynamic} instruction is not included as it does not
allow static typechecking and so should not be used for SCJ.
The requirement for all classes to be loaded at startup greatly
simplifies the semantics of several instructions since dynamic class
loading does not need to be considered.
It also means that method lookup tables can be precomputed, which
simplifies method lookup and means that the semantics of the
\texttt{invokevirtual} and \texttt{invokeinterface} instructions are
the same so they do not both need to be included.

In terms of concurrency considerations, we are assuming our SCJVM to
be single processor and so we do not need to have more than one
interpreter.
We also assume that thread switches can only occur between bytecode
instructions in the interpreter.
That means that both the bytecode instructions and the portions of
execution occuring in the launcher are atomic, which greatly
simplifies the model since thread switches at any time do not have to
be accounted for. 

With the above assumptions in mind, the bytecode instructions in our
subset are as follows:
\begin{itemize}
\item \texttt{aconst\_null}
\item \texttt{aload}
\item \texttt{areturn}
\item \texttt{astore}
\item \texttt{dup}
\item \texttt{getfield}
\item \texttt{invokevirtual}
\item \texttt{invokespecial}
\item \texttt{new}
\item \texttt{putfield}
\item \texttt{return}
\end{itemize}

The instruction \texttt{dup} is included as an example of a simple
instruction that operates on the operand stack and was chosen for its
frequent occurence in object intialisation.
Other instructions that do simple operand stack manipulation,
including the arithmetic instructions, can be specified similarly.

Instructions that create object references and pass them around are
also included to allow the full range of object manipulations.
However, arrays are not included as they would require additional
instructions and could be emulated, albeit inefficiently, with the
instructions given here.

Both \texttt{invokevirtual} and \texttt{invokespecial} are supplied as
\texttt{invokespecial} chooses the method to invoke in a different way
and is required for object initialisation.

\input{\string~/SCJ-VM/James/Bytecode/classes.zed}

\input{\string~/SCJ-VM/James/Bytecode/code_area.zed}

\input{\string~/SCJ-VM/James/Bytecode/memory.zed}

\input{\string~/SCJ-VM/James/Bytecode/stack_frames.zed}

\input{\string~/SCJ-VM/James/Bytecode/interpreter.zed}

\input{\string~/SCJ-VM/James/Bytecode/launcher.zed}

\input{\string~/SCJ-VM/James/Bytecode/complete_cee.zed}

\chapter{Conclusions}
\label{conclusions-chapter}
% three sections: summary of contributions, related work, and future
% work
In this chapter we conclude by summarising the contributions of this
dissertation in Section~\ref{summary-section}.
We then discuss some related work in
Section~\ref{related-work-section}, and the direction of future work
in Section~\ref{future-work-section}.

\section{Summary of Contributions}
\label{summary-section}

In this dissertation we have considered the safety-critical variant of
Java and some virtual machines designed to run programs written in it.
We have concluded that none of the virtual machines is formally
verified and that many of them precompile programs to native code.
Given the need for a formally verified virtual machine, we have stated
our aim to specify a framework within which an SCJ virtual machine can
be verified

Having noted that SCJ virtual machines employ compilation, we have
surveyed some of the work on compiler correctness, particularly how it
relates to Java compilation, and seen that there are two
approaches:~the commuting-diagram approach and the algebraic approach.
We have decided to adopt the algebraic approach and chosen \Circus{}
as a specification language.

As some preliminary work in specifying an SCJ virtual machine, we have
identified the requirements of the virtual machine services required
to support SCJ programs.
We have also constructed a formal model of those requirements in the
\Circus{} specification language.

Contact with one of the authors of the SCJ specification has allowed
us to obtain clarifications where the specification is unclear.
The work of constructing the formal model has helped in the
identification of the areas that require clarification.
It may be noted that the interface we have defined is not the only one
that can support SCJ, though we believe that the overall functionality
must be present in all SCJ virtual machines in some way.
% need more reflection on the preliminary results, check the
% conclusions of the JTRES paper for material

\section{Related Work}
\label{related-work-section}

Our work is done in the context of a wider effort to facilitate fully
verified Safety-Critical Java programs.
There has already been work on generating correct SCJ programs from
\Circus{} specifications~\cite{cavalcanti2011, cavalcanti2013} and
formalisation of the SCJ memory model~\cite{cavalcanti2011a}.
These works allow for verification of SCJ programs, with our work
forming the next stage of ensuring those programs can be run
correctly.

Though our work addresses the execution of Java bytecode, it must
still be ensured that SCJ programs can be compiled to bytecode
correctly.
However, since SCJ does not make any syntactic changes to Java and the
semantic changes can be dealt with at the level of Java bytecode, a
standard Java compiler suffices for SCJ.
As discussed earlier, there has been plenty of work on correct
compilation of Java programs~\cite{klein2006, strecker2002,
  lochbihler2010, duran2005, stark2001} so it can be seen that there
is already sufficient work to permit correct compilation to Java
bytecode.
This then leaves us with correct SCJ programs in Java bytecode and the
focus of our work is on the next stage of running those programs.

Finally, as we are adopting the approach of compilation to C, it must
also be ensured that the C code can be compiled correctly.
We note that there has been much work on verified C
compilation~\cite{leroy2009a, leroy2009b, leroy2012, leinenbach2005,
  blazy2006} and, in particular, that the CompCert project provides a
functioning formally verified C compiler that can be used.
So our proposed work is the final piece needed for complete
verification of SCJ programs down to executable code.

\section{Future Work}
\label{future-work-section}

Our future work will involve proving the correctness of the formal
model of the virtual machine services and specifying the core
execution environment.
The formal model of the virtual machine services that we have created
needs to be validated and this may require revision of the formal
model due to errors uncovered in the process of proving essential
properties.

The specification of the core execution environment will be a proof of
correct compilation from Java bytecode to C using the algebraic
approach.
As already discussed, this will involve defining the semantics of Java
bytecode and C in terms of \Circus{} and proving refinement laws
between them.
We will mechanise these proofs in the Isabelle proof assistant in
order to have assurance that the proofs are sound.

Beyond the scope of our work, possible future work includes the
verification of an SCJ virtual machine using our framework or even the
creation of a correct-by-construction virtual machine from our
specification.
The option of deriving a correct virtual machine from our
specification may be more desirable than verifying an existing one.
This is because virtual machines can often be complex and therefore
difficult to verify in a structured way.
Moreover, while the effort of proving a virtual machine correct may
uncover bugs, it may be a challenge to fix them.
Also, the design of an existing virtual machine may not exactly meet
the structure of our specification, requiring restructuring to allow
the proof effort to begin.

On the other hand, the fact that \Circus{} allows for refinement means
that a correct virtual machine can be constructed from our model in a
stepwise and modular fashion, being shown to be correct at each stage
of the process.
Facilitating such work is the ultimate aim of our work, in order to
provide for the correct running of SCJ programs.

\raggedright \printbibliography

\appendix

\chapter{Z/Eves Theorems and Proofs}

\input{\string~/SCJ-VM/James/additional_lemmas.zed}

\section{Proofs of Additional Toolkit Lemmas}
\label{additional-lemmas-proofs-section}
\scriptsize

\input{\string~/SCJ-VM/James/additional_lemmas_sets_proofs.zed}

\input{\string~/SCJ-VM/James/additional_lemmas_relations_proofs.zed}

\input{\string~/SCJ-VM/James/additional_lemmas_numbers_proofs.zed}

\input{\string~/SCJ-VM/James/memorymanager.zed}


\end{document}

%  LocalWords:  modularise certifiability verifiers mechanisations checkable
%  LocalWords:  aperiodically schedulability associativity nondeterministic CSP
%  LocalWords:  precompiled precompilation disjunction schemas instantiation
%  LocalWords:  nondeterministically boolean datatype SCJVM stepwise
