\chapter{Evaluation}
\label{evaluation-chapter}

In this chapter, we evaluate our model and compilation strategy, using
several approaches.
First, we consider what assurances can be gained from mechanisation of
the model and proofs of the compilation rules.
In addition, we compare code produced by our strategy to that produced by
icecap, using some examples to evaluate the strategy.
% TODO: more that we can add here?
We note, finally, that the process of constructing the model already
embeds important validation effort, via numerous reviews of the
standard, and close interaction with the standardisation committee,
which led to some changes to the standard.

Next, in Section~\ref{mechanisation-of-models-section}, we consider
the assurances gained from mechanisation of the models that form the
starting point of the strategy.
In Section~\ref{proofs-of-laws-section}, we discuss the proofs of the
compilation rules used in the strategy and how they provide assurances
of the correctness of the strategy.
Afterwards, in Section~\ref{tool-support-section}, we consider
mechanisation of the strategy and then, in
Section~\ref{examples-section}, we evaluate the strategy with some
examples.
Finally, we conclude in
Section~\ref{evaluation-final-considerations-section}.


\section{Mechanisation of Models}
\label{mechanisation-of-models-section}

% TODO: rephrase this
The correctness of our compilation strategy relies on the correctness
of the models used as input to the compilation strategy.
Their correctness relies on the inputs to the models meeting the
assumptions made in Section~\ref{compilation-assumptions-section}.
If these assumptions are not met, then the behaviour of model is not
correct and the compilation strategy cannot be applied.
For example, if the sequence of instructions in the program causes the
operand stack to overflow the maximum stack size, the invariant of
$StackFrame$ is violated and program's behaviour is chaotic.
Our compilation strategy cannot be applied to such a program, since no
stack slots are created beyond the maximum stack size to handle such a
situation in the strategy, and it is not clear what the expected C
code would be.

As discussed in Section~\ref{cee-validation-section}, the fact that
the models are written in CZT ensures they have correct syntax and
types.
CZT performs this checking continuously and flags up errors as they
occur, so they can be quickly corrected during the writing of the
models.

We have also performed some proofs on the Z schemas defining the
semantics of the bytecode instructions, using Z/EVES 2.4.1 with CZT as
its user interface.
There are two main groups of results.
The first is domain check proofs, ensuring partial functions are
not applied outside their domain.
These are proof obligations generated by Z/EVES, and so do not have
corresponding theorems stated.
These proofs are not required for schemas that do not directly
reference partial functions.

The second group of results is precondition proofs.
These require that a final state exists for the schema, which ensures
that the requirements of the schema are not contradictory.
Stating and proving these theorems also extracts the preconditions of
the operations, since those must be stated as assumptions of the
theorems.

The preconditions we have found include those required to avoid
operand stack overflows and underflows, that local variable indices
are within the range of the local variable array, and that
program-address updates do not go outside of the current method's
bytecode array.
These conditions are ensured by standard JVM bytecode verification,
which we assume inputs to the strategy pass.
The existence of at least one stack frame is also required for
bytecode instructions to execute, and this property is ensured by the
condition on the loop in the $Running$ action.

A further precondition required by the interpreter operations is that
the value $cs$ is such that the class and method in which a program
address occurs is unique.
This condition is required to ensure that the current class and method
can be uniquely determined from the value of $pc$.
This is required by the invariant of $InterpreterState$, but need only
be fulfilled as a precondition when a new stack frame is created,
since it can be ensured from the invariant on the initial state for
the other operations.
This condition on $cs$ is reasonable since the bytecode instructions
for each method should be at separate addresses in $bc$.

% TODO: these proofs will be removed in the main thesis
The statements of the theorems proved can be found in
Appendix~\ref{stack-frames-theorems-appendix} and
Appendix~\ref{interpreter-theorems-appendix}, with their corresponding
proofs in Appendix~\ref{stack-frames-proofs-appendix} and
Appendix~\ref{interpreter-proofs-appendix}.
We have also proved various additional lemmas in the course of
constructing these proofs.
Those which are specific to the model are listed along with the
precondition theorems in Appendix~\ref{stack-frames-theorems-appendix}
and Appendix~\ref{interpreter-theorems-appendix}.
Some of them are general facts that could be of use in other theorems,
which are listed in Appendix~\ref{additional-lemmas}.

\section{Proofs of Laws}
\label{proofs-of-laws-section}

The correctness of our compilation strategy is ensured by the
correctness of the individual compilation rules.
We prove these rules in terms of algebraic laws, whose correctness is
known.
This gives assurance that no step of the compilation strategy involves
applying a transformation that changes the semantics of the input
program.

We adopt an algebraic style of proof, in which the algebraic laws are
applied one-by-one to transform the left-hand-side of a rule into its
right-hand-side.
This ensures that the term obtained in each step of the proof is shown
to be a refinement of, or equal to, that of the previous step, by
application of a known law.
The overall proof then follows from the transitivity of refinement.
Thus, every step of the proof is justified formally and this can be
easily seen from the layout of the proof.

The laws used in the proofs come from various sources.
Some are existing laws taken from~\cite{oliveira2006}
and~\cite{miyazawa2012}, which have already been proved as part of
those works, and so can be safely reused.
We have also used a few ZRC laws from~\cite{cavalcanti1998}, which can
be applied to \Circus{} since the semantics of ZRC are compatible with
those of \Circus{}, by Theorem 4.3 from~\cite{oliveira2006}.
Standard least-fixed-point laws, stated in~\cite{hoare1998} are also
applied to \Circus{} recursion, since it defined using
least-fixed-points.
Some laws follow as a trivial consequence of the definitions given in
these sources, such as Law~[\nameref{action-intro-law}], which follows
from the definition of process refinement, which does not reference
actions not used in the main action of a process.

We have proved other laws using the proof assistant
Isabelle~\cite{nipkow2002} with its implementation of
UTP~\cite{foster2015}.
The constructs supported by that implementation limit the types of
laws that may be proved, but we have proved several laws relating to
conditionals, assumptions, and assignment.
In the case of conditionals, we contributed an implementation of
\Circus{} conditionals to Isabelle/UTP.
This has allowed us to prove laws more general than those that have
been proved previously, since previous laws have used the fact that
conditionals can be converted to external choice, which requires that
the guards be disjoint and provide complete coverage.
We require these more general laws to perform transformation of the
$Running$ action during the elimination of program counter, since not
all program counter values have a corresponding bytecode instruction,
so we cannot ensure coverage.
Our work on this has now been integrated into Isabelle/UTP itself.

Some of the algebraic laws are applied directly in our strategy, and
may be found in
Appendix~\ref{compilation-strategy-algebraic-laws-section} after the
compilation rules specific to each stage of the strategy.
A full list of the algebraic laws used in this thesis, including both
those used in our compilation strategy and those used in the proofs of
the compilation rules, can be found in
Appendix~\ref{algebraic-laws-appendix}.

% discuss compilation rules and their proofs
% explain the importance of the algebraic proof style
% explain source of laws used for proofs

\section{Tool Support}
\label{tool-support-section}

In addition to proving the individual compilation rules, it also is
useful to be able to automatically generate the code resulting from
the strategy in order to validate it.
This allows for consideration of the issues involved in handling
actual SCJ programs and shows how the strategy as a whole fits
together to produce the final code.
It also facilitates the consideration of examples, which provides
additional validation of the strategy.

We have thus created a simple prototype of the strategy to transform
Java class files to the corresponding code generated by the strategy.
This prototype is written in Java, using the Apache bytecode emulation
library for reading class files so that real output from the standard
Java compiler can be used directly.
It outputs the \Circus{} code that results from applying the
compilation strategy to the input files.

\begin{figure}[p]
  \begin{center}
    \begin{tikzpicture}
      % \begin{class}{ClassFileModelConverter}{0,0}
      %   \operation{+ \uline{main(args : String[])}}
      % \end{class}

      \umlclass{Model}{
        $\cdots$
      }{
        + toModelString() : String \\
        + doEliminationOfProgramCounter() : EPCModel \\
        - methods() : HashSet\textless{}FullMethodID\textgreater{} \\
        - allMethodsSeparated(newModel : EPCModel) : boolean \\
        $\cdots$
      }

      \umlclass[x=-3.5cm,y=-4cm]{ClassModel}{}{}

      \umlclass[x=3.5cm,y=-4cm,type=abstract]{ModelBytecode}{}{}

      \umlclass[alias=aconstnull,x=8cm,y=-2cm]{ACONST\_NULL}{}{}
      \node at (8cm,-3.8cm) {\Huge  $\vdots$};
      \umlclass[x=8cm,y=-6cm]{RETURN}{$\cdots$}{$\cdots$}

      \umlinherit[geometry=-|-]{aconstnull}{ModelBytecode}
      
      \umlinherit[geometry=-|-]{RETURN}{ModelBytecode}

      \umluniaggreg[geometry=|-,anchor1=-110,arg2=classes,mult2=0..*,pos2=1.4,arm2=-0.1cm]{Model}{ClassModel}
      \umluniaggreg[geometry=|-,anchor1=-90,arg2=bytecodes,mult2=0..*,pos2=1.6,arm2=-0.1cm]{Model}{ModelBytecode}

      \umlclass[x=0cm,y=-8.5cm]{EPCModel}{
        $\cdots$
      }{
        + addMethod(name : FullMethodID, actions : CircusAction[]) \\
        + toModelString() : String \\
        + doEliminationOfFrameStack() : EFSModel \\
        - methods() : HashSet\textless{}FullMethodID\textgreater{} \\
        - allMethodsSeparated(newModel : EPCModel) : boolean \\
        $\cdots$
      }

      \umluniaggreg[geometry=|-|,anchor1=130,arg2=classes,mult2=0..*,pos2=2.8]{EPCModel}{ClassModel}

      \umlclass[x=0cm,y=-13cm,type=abstract]{CircusAction}{}{
        \umlvirt{+ expandWithClassInfo(classInfo : ClassModel) : CircusAction} \\
        \umlvirt{+ doEFSDataRefinement(stackDepth : int) : CircusAction[]} \\
        $\cdots$
      }

      \umlclass[alias=handleaconstnullepc,x=7cm,y=-15.5cm]{HandleAconst\_nullEPC}{
        $\cdots$
      }{
        $\cdots$
      }
      \node at (7cm,-17.3cm) {\Huge  $\vdots$};
      \umlclass[x=7cm,y=-19.5cm]{Assignment}{
        $\cdots$
      }{
        % + getVar() : String \\
        % + getExpr() : String() \\
        $\cdots$
      }

      \umlinherit[geometry=-|,anchor2=-20]{handleaconstnullepc}{CircusAction}
      
      \umlinherit[geometry=-|,anchor2=-20]{Assignment}{CircusAction}

      \umluniaggreg[geometry=|-|,anchor1=-90,arg2=methodActions,mult2=0..*,pos2=2.8]{EPCModel}{CircusAction}

      \umlclass[x=0cm,y=-17cm]{EFSModel}{
        $\cdots$
      }{
        + toModelString() : String \\
        $\cdots$
      }

      \umluniaggreg[geometry=|-|,anchor1=90,arg2=methodActions,mult2=0..*,pos2=2.8]{EFSModel}{CircusAction}
      
      % \aggregation{Model}{classes}{0..*}{ClassModel}
      % \aggregation{Model}{bytecodes}{0..*}{ModelBytecode}
    \end{tikzpicture}
  \end{center}
  \caption{Class diagram for our implementation of the compilation
    strategy}
  \label{implementation-class-diagram-figure}
\end{figure}

One benefit of having a prototype implementation of the compilation
strategy is that it validates our reasoning in constructing the
compilation strategy, since the code generated for the examples has
the expected form.
To ensure we get the most benefit from this, we follow the strategy
and the form of the compilation rules as closely as possible in our
implementation.
Some of the classes used in our implementation, and the relationships
between them are shown in
Figure~\ref{implementation-class-diagram-figure} to ilustrate our
explanation of it. 
Our implementation begins by reading the each input class file and
extracting the information into \texttt{ClassModel} classes and
\texttt{ModelBytecode} classes.
\texttt{ClassModel} represents the $Class$ type from our model and
makes available all the information represented in that type.
\texttt{ModelBytecode} is an abstract class whose subclasses represent
individual bytecode instructions; it represents the $Bytecode$ type
from our model.
The set of \texttt{ClassModel} structures and array of
\texttt{ModelBytecode}s are collected together into a \texttt{Model},
representing the inputs to the compilation strategy.

The application of the first stage of the compilation strategy to a
\texttt{Model} is initiated by invocation of its
\texttt{doEiminationOfProgramCounter()} method.
This returns an \texttt{EPCModel} object, which represents the $ThrCF$
process generated from the inputs represented by the \texttt{Model}.
The \texttt{doEiminationOfProgramCounter()} method applies each step
of Algorithm~\ref{epc-algorithm}.
It begins by replacing each bytecode instruction with the \Circus{}
actions that result from applying bytecode expansion to it.
We represent \Circus{} actions by subtypes of an abstract class
\texttt{CircusAction}.
These subtypes represent both general \Circus{} constructs such as
variable blocks, conditionals and assignment, and references to
specific actions in our model, such as the $Handle{*}EPC$ actions.
The sequences of actions produced by bytecode expansion are placed
into an array of arrays of \texttt{CircusAction}s, representing the
branches of the choice over $pc$ in $Running$.
We test the types of the actions in these sequences to check if they
match the compilation rules of the strategy, and update the sequence
of actions in a branch accordingly.
We also construct a control-flow graph, which we use to guard the
application of some rules as indicated in the strategy, and which is
reconstructed after the application of a compilation rule.
The sequence of actions corresponding to entry point of a method whose
control-flow graph consists of a single node are added to the
\texttt{EPCModel} during method separation, with their $pc$
assignments removed when they are added.

The application of the elimination of frame stack stage to the
\texttt{EPCModel} is performed by its
\texttt{doEliminationOfFrameStack()} method, which returns a
\texttt{EFSModel} representing the $CProg$ process generated after
this stage.
In our implementation we apply the rules of this stage by traversing
the actions of each method, checking for actions that match the form
of the rules.
Rules that operate on sequences of more than one rule are applied by
private methods of \texttt{EPCModel}, whereas those that affect only a
single action are applied by methods of the \texttt{CircusAction}
classes.
We group together the application of similar rules, for example
\texttt{expandWithClassInfo()} applies the rules on
lines~\ref{algorithm-apply-refine-PutfieldSF}
to~\ref{algorithm-apply-refine-NewSF} of
Algorithm~\ref{introduce-variables-algorithm}, which make use of
information of the value of $frameClass$, and
\texttt{eliminateVarBlocks()} applies the rules on
lines~\ref{algorithm-apply-eliminate-value1-value2-conditional-rule}
to~\ref{algorithm-argument-variable-elimination} of
Algorithm~\ref{introduce-variables-algorithm}, which eliminate extra
varible blocks around various constructs.
The \Circus{} model resulting from this stage is extracted as a
\texttt{String} from the \texttt{EFSModel} and written to an output
file.

As our prototype is just for the purposes of quickly validating the
strategy, we have not performed a direct formal verification of its
implementation.
However, since we have applied the compilation rules in the
implementation in a way that matches the form of the rules in the
strategy, which are proved, we can know its correctness.
The correctness of the implementation is further validated by loading
the output of the prototype into CZT to ensure that it is well-formed,
and checking the output to ensure it has the expected form.

There have been various considerations raised in producing this
prototype and applying it to examples.
The first is that the bytecode instructions produced by the Java
compiler for most SCJ programs are not restricted to the
representative subset of instructions described in
Section~\ref{cee-bytecode-subset-subsection}.
However, since this is a representative subset, the strategy can be
easily expanded to handle the missing instructions by analogy to the
instructions in the subset.
For example binary operation bytecodes can have their semantics
defined in a similar way to \texttt{iadd}, with compilation rules to
handle them similar to those for \texttt{iadd} (and their
corresponding proofs similar).
Conditional instructions can handled in a similar way to
\texttt{if\_icmple} during bytecode expansion, and subsequently handled
by existing compilation rules, since the loop and conditional
introduction rules operate on assignments of the form
$pc := \IF b \THEN x \ELSE y$, and so are agnostic to the condition
checked.

Array instructions are slightly more challenging to replicate in the
strategy, but can be represented in programs using classes that
contain the individual slots of the array as fields. 
These fields can then be accessed using methods that select the
appropriate field with conditionals over an array index.
A full implementation would replace these method calls with
specialised communications with the struct manager, which would handle
them using C arrays.
Although this would require changes to the object/struct manager, it
would be relatively simple in terms of the strategy as the structure
of the arrays would not change during compilation and very little
would need to be performed on the instructions in the interpreter.

A further consideration is that of how to represent the class, field,
and method identifiers used in the bytecode.
In the model these are represented by given sets, since their
representations do not matter provided they can be distinguished from
one another and information necessary to the operation of the strategy
(specifically, the number of arguments to a method identifier and
whether it denotes an instance initialisation method) can be gleaned
from them.
For simplicity, we just use the identifier strings supplied in the
input Java class files, concatenating method and field names with
their type signatures, and removing or replacing characters that are
not valid in \Circus{} identifiers.
% However, many of these identifiers are quite long, since they use
% fully qualified class names, so we generally shorten them when
% presenting examples, provided the identifiers are still unique.
% The shortenings performed are generally elimination of packages names
% from class names, and removal of type signatures from method
% identifiers when two methods do not have the same name (initialisation
% method identifiers have a shortened version of their class name
% prepended to distinguish them).

Since we apply the compilation rules in our implementation matching
the form of the rules given our strategy, we can observe how the
individually correct compilation rules fit together in the strategy.
It has highlighted the need to take care concerning the extent of
variable blocks.
In particular, the loop and conditional introduction rules must match
the variable block introduced by the expansion of the
\texttt{if\_icmple} bytecode instruction. 
We also found that Rule~[\nameref{resolve-normal-method-rule}] must
extend the $poppedArgs$ variable block to cover the reference to the
method action it introduces, in order to match the combination of
$IntepreterNewStackFrame$ operation and method action reference in
Rule~[\nameref{arguments-introduction-rule}] and that the return
action must be distributed outside of the variable blocks surrounding
conditionals in Rule~[\nameref{conditional-dist-rule}].
The form of the methods resulting from the elimination of program
counter also made clear the need for $Poll$ actions before $Running$
in $Started$ and $MainThread$, in order to match method calls
introduced in the body of methods.
% The form of the code generated for the examples can be seen in the
% next section, where we consider the examples themselves.


% discuss mechanisation of strategy
% explain considerations surrounding bytecode subset
% explain what confidence this brings

\section{Examples}
\label{examples-section}

% illustrate with some examples
% compare to icecap

\section{Final Considerations}
\label{evaluation-final-considerations-section}